{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Importing libraries</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.6.14\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda update scikit-learn --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import keras\n",
    "import itertools\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from skimage import feature, data, io, measure\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Extracting zip files to classify images</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['distractions/c1/', 'distractions/c1/img_115.jpg', 'distractions/c1/img_149.jpg', 'distractions/c1/img_357.jpg', 'distractions/c1/img_448.jpg', 'distractions/c1/img_6.jpg', 'distractions/c2/', 'distractions/c2/img_186.jpg', 'distractions/c2/img_253.jpg', 'distractions/c2/img_258.jpg', 'distractions/c2/img_271.jpg', 'distractions/c2/img_94.jpg', 'distractions/c3/', 'distractions/c3/img_204.jpg', 'distractions/c3/img_207.jpg', 'distractions/c3/img_216.jpg', 'distractions/c3/img_244.jpg', 'distractions/c3/img_5.jpg']\n",
      "['c1', 'c2', 'c3']\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile((os.environ['DSX_PROJECT_DIR']+'/datasets/distractions.zip'),'r')\n",
    "paths = zip_ref.namelist() \n",
    "print(paths)\n",
    "classes_required=[]\n",
    "for path in paths:\n",
    "    zip_ref.extract(path)\n",
    "    temp=path.split('/') \n",
    "    if len(temp) == 3:\n",
    "        if temp[1] not in classes_required:\n",
    "            classes_required.append(temp[1])\n",
    "print(classes_required)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Defining the testing, training and valdiation sets</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 3\n",
    "batch_size_val = 15\n",
    "batch_size_test = 15\n",
    "num_classes= 3\n",
    "intereseted_folder='distractions'\n",
    "STANDARD_SIZE=(224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Converting Data Format according to the backend used by Keras\n",
    "'''\n",
    "datagen=keras.preprocessing.image.ImageDataGenerator(data_format=K.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Extracting training dataset...</h3></b> Do this only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"There is no item named '/user-home/1002/DSX_Projects/Distraction Detection/datasets/distractions/c1' in the archive\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-5af9ce038dde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mzip_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DSX_PROJECT_DIR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/datasets/distractions.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DSX_PROJECT_DIR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/datasets/distractions/c1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, member, path, pwd)\u001b[0m\n\u001b[1;32m   1482\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mforce_zip64\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mzinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.05\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mZIP64_LIMIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seekable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m         \u001b[0mzinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1523\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1524\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36mgetinfo\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1279\u001b[0m         print(\"%-46s %19s %12s\" % (\"File Name\", \"Modified    \", \"Size\"),\n\u001b[1;32m   1280\u001b[0m               file=file)\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mzinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m             \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%d-%02d-%02d %02d:%02d:%02d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mzinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             print(\"%-46s %s %12d\" % (zinfo.filename, date, zinfo.file_size),\n",
      "\u001b[0;31mKeyError\u001b[0m: \"There is no item named '/user-home/1002/DSX_Projects/Distraction Detection/datasets/distractions/c1' in the archive\""
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(os.environ['DSX_PROJECT_DIR']+'/datasets/distractions.zip', 'r')\n",
    "zip_ref.extract((os.environ['DSX_PROJECT_DIR']+'/datasets/distractions/c1'))\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''Input the Training Data\n",
    "''' \n",
    "import zipfile\n",
    "#zip_ref = zipfile.ZipFile(os.environ['DSX_PROJECT_DIR']+'/datasets/distractions.zip', 'r')\n",
    "#zip_ref.extract((os.environ['DSX_PROJECT_DIR']+'/datasets/'))\n",
    "#zip_ref.close()\n",
    "train_path = os.environ['DSX_PROJECT_DIR']+'/datasets/distractions' \n",
    "print(train_path)\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=classes_required, batch_size=batch_size_train)\n",
    "type(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile((os.environ['DSX_PROJECT_DIR']+'/datasets/val_data.zip'),'r')\n",
    "paths = zip_ref.namelist() \n",
    "print(paths)\n",
    "classes_required=[]\n",
    "for path in paths:\n",
    "    zip_ref.extract(path)\n",
    "    temp=path.split('/') \n",
    "    if len(temp) == 3:\n",
    "        if temp[1] not in classes_required:\n",
    "            classes_required.append(temp[1])\n",
    "print(classes_required)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(os.environ['DSX_PROJECT_DIR']+'/datasets/val_data.zip', 'r')\n",
    "zip_ref.extractall((os.environ['DSX_PROJECT_DIR']+'/datasets/'))\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''Input the Validation Data\n",
    "'''\n",
    "\n",
    "val_path = os.environ['DSX_PROJECT_DIR']+'/datasets/val_data'\n",
    "val_batches = ImageDataGenerator().flow_from_directory(val_path, target_size=(224,224), classes=classes_required, batch_size=batch_size_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(os.environ['DSX_PROJECT_DIR']+'/datasets/test_data.zip', 'r')\n",
    "zip_ref.extractall((os.environ['DSX_PROJECT_DIR']+'/datasets/'))\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Input the Test Data\n",
    "'''\n",
    "test_path = os.environ['DSX_PROJECT_DIR']+'/datasets/test_data'\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=classes_required, batch_size=batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs, test_labels = next(test_batches)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test= [ np.where(r==1)[0][0] for r in test_labels ]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Create the CNN model</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16()\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vgg16_model) #This is a Keras Functional API need to convert to sequential\n",
    "model = Sequential() #Iterate over the functional layers and add it as a stack\n",
    "for layer in vgg16_model.layers:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers.pop()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers: #Since the model is already trained with certain weights, we dont want to change it. Let it be the same\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(3, activation='sigmoid')) # Add the last layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complie the model\n",
    "model.compile(Adam(lr=.00015), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_batches, steps_per_epoch=20, \n",
    "                    validation_data=val_batches, validation_steps=20, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Extracting dataset for testing out model</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile((os.environ['DSX_PROJECT_DIR']+'/datasets/sample3.zip'),'r')\n",
    "paths = zip_ref.namelist()\n",
    "\n",
    "print(paths)\n",
    "for path in paths:\n",
    "    print(zip_ref.extract(path))\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Testing the model and getting the predictions</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[] \n",
    "def convert_to_image(X):\n",
    "    '''Function to convert all Input Images to the STANDARD_SIZE and create Training Dataset\n",
    "    '''\n",
    "    for f in paths:\n",
    "        #fobj=get_file(f)\n",
    "        #print(type(fobj))predictions= model.predict(X_test)\n",
    "        if os.path.isdir(f):\n",
    "            continue\n",
    "        img= PIL.Image.open(f)\n",
    "        img = img.resize(STANDARD_SIZE) \n",
    "        img_test = img\n",
    "        img=np.array(img)\n",
    "        X.append(img)\n",
    "        #print(X_train)\n",
    "    #print(len(X_train))\n",
    "    return X\n",
    "X_test=np.array(convert_to_image(X_test))\n",
    "datagen.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=[]\n",
    "# for i in range(len(predictions)):\n",
    "#     y_pred.append(np.argmax(predictions[i]))\n",
    "# print(y_pred) \n",
    "# print(i) \n",
    "# print(y_pred[0])\n",
    "# print(paths)\n",
    "# print(len(predictions)) \n",
    "# print(np.argmax(predictions[i])) \n",
    "# j = 0\n",
    "# for i in y_pred:\n",
    "#     print(paths[y_pred[j]])\n",
    "#     j = j + 1 \n",
    "\n",
    "\n",
    "\n",
    "y_pred=[]\n",
    "for i in range(len(predictions)):\n",
    "    y_pred.append(np.argmax(predictions[i]))\n",
    "y_pred\n",
    "j = 0\n",
    "for i in y_pred:\n",
    "    print(paths[y_pred[j]])\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classes_required)\n",
    "index= classes_required.index('c1') #Edit this class index here to retrieve image of that class \n",
    "index1= classes_required.index('c2') #Edit this class index here to retrieve image of that class\n",
    "index2= classes_required.index('c3') #Edit this class index here to retrieve image of that class\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == index:\n",
    "        print(\"Image that has been classified as a c1 is: \", paths[i]) \n",
    "    elif y_pred[i] == index1:\n",
    "        print(\"Image that has been classified as a c2 is: \", paths[i]) \n",
    "    elif y_pred[i] == index2:\n",
    "        print(\"Image that has been classified as a c3 is: \", paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_batches, steps=1, verbose=0)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions\n",
    "y_pred=[]\n",
    "for i in range(len(predictions)):\n",
    "    y_pred.append(np.argmax(predictions[i]))\n",
    "print(y_pred)\n",
    "#plots(test_imgs, titles=y_pred)\n",
    "\n",
    "ctr=0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        ctr=ctr+1\n",
    "res = ctr/len(y_pred)*100\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Deploying the model as a WML model</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "wml_credentials = {\n",
    "                    \"url\": \"https://52.116.34.53\",\"username\": \"contestant2\",\"password\": \"lkjhgf65\", \"instance_id\": \"icp\"               \n",
    " }\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_props = {client.repository.ModelMetaNames.NAME: \"A sample model\", client.repository.ModelMetaNames.FRAMEWORK_NAME: 'tensorflow',\n",
    "        client.repository.ModelMetaNames.FRAMEWORK_VERSION: '1.12',\n",
    "        client.repository.ModelMetaNames.RUNTIME_NAME: 'python',\n",
    "        client.repository.ModelMetaNames.RUNTIME_VERSION: '3.5',\n",
    "        client.repository.ModelMetaNames.FRAMEWORK_LIBRARIES: [\n",
    "         {\"name\": \"keras\", \"version\": \"2.2.4\"}\n",
    "    ]}   \n",
    "model_details = client.repository.store_model(model,  model_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
